{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4a63ffd-5763-4186-ab61-1aed99066293",
   "metadata": {},
   "source": [
    "## Nodes to Delete Data From"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61899461-1e03-479a-bd9b-b6e0004f1ad1",
   "metadata": {},
   "source": [
    "This script identifies the nodes (parent and child) that my new thermo falls in or under. \n",
    "The plan is: \n",
    "1) Identify which preexisting nodes my new thermo falls under\n",
    "2) Identify which libraries were used to previously train those \n",
    "3) Delete that data from the node \n",
    "\n",
    "Then finally, we can use Hao Wei's script to discover \"missing\" groups and refit the thermo then. This refitting will include the identified libraries in step 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05342793-608a-400d-8e33-97d6e02a350a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4250d484-515c-4f4a-a0ae-e1c0b80dabf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "495c890b-6519-4dcc-9856-75a4c5fbe08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rmgpy import settings\n",
    "from rmgpy.data.thermo import ThermoDatabase, ThermoData, remove_thermo_data, add_thermo_data\n",
    "import rmgpy.molecule.group as gr\n",
    "from rmgpy.molecule.group import Group, GroupAtom, GroupBond\n",
    "from rmgpy.data.base import Entry\n",
    "from rmgpy.data.base import LogicOr\n",
    "from rmgpy.molecule.atomtype import ATOMTYPES\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "from copy import copy, deepcopy\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "plt.style.use(\"seaborn-poster\")\n",
    "import numpy as np\n",
    "\n",
    "from copy import deepcopy\n",
    "from sklearn.linear_model import RidgeCV,LassoCV,ElasticNetCV,LinearRegression\n",
    "from sklearn.linear_model import Ridge,Lasso,ElasticNet\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc3dcd6-2f94-4c32-91cf-f76788619ea4",
   "metadata": {},
   "source": [
    "# User inputs\n",
    "\n",
    "Input thermo libraries to fit thermo groups from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f22d845f-c1b9-45f2-be2c-c58592cf362c",
   "metadata": {},
   "outputs": [],
   "source": [
    "libraries = [\"C1_C2_Fluorine\",\n",
    "            \"C1_C3_hydrofluorocarbons_NIST\",  #obtained via email by Linteris on 3/10/23\n",
    "             \"NCSU_C2_C8_PFAS\", \n",
    "             \"PFCA_thermo\", \n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a2c160-92c1-4d9a-8df0-8aab0cf250d0",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c45e176-c2fe-46a2-8801-9fac3b0c7884",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helperfunctions import get_neighbors, make_bonds, make_group, make_neighbor_name, make_group_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cbd521-103d-4e39-abf7-372ce0e9f33b",
   "metadata": {},
   "source": [
    "## 1.1 Special groups that we should not fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d1a0dac-2563-4c91-8369-7f781d8df8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_list = [\n",
    "    'O0sc-N5dc',\n",
    "    'S2d-CS',\n",
    "    'S2d-C2d',\n",
    "    'O2d-N5dc',\n",
    "    'O2d-CO',\n",
    "    'O2d-S6dd',\n",
    "    'O2d-N3d',\n",
    "    'O2d-S4dd',\n",
    "    'O2d-S4d',\n",
    "    'O2d-Cdd',\n",
    "    'Cb-CSCbCb',\n",
    "    'Cdd-CdO2d',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb863c53-8b82-499d-a2e7-6069a375c818",
   "metadata": {},
   "source": [
    "# 2 Fit thermo groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0d8479e-2f37-4a3a-8b11-06db6feadf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "database = ThermoDatabase()\n",
    "database.load(os.path.join(settings['database.directory'],\"thermo\"),\n",
    "             libraries = libraries,\n",
    "             depository=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58e76ee4-9aac-4441-8b50-a22a567ad1a2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================\n",
      "Current species is F (F)\n",
      "\n",
      "GAV not built for radicals. Passing this species.\n",
      "\n",
      "========================================================\n",
      "Current species is F2 (F2)\n",
      "\n",
      "Estimated thermo via GAV is already good.\n",
      "This is a hydrogen or halogen\n",
      "This is a hydrogen or halogen\n",
      "\n",
      "========================================================\n",
      "Current species is HF (FH)\n",
      "\n",
      "Estimated thermo is off.\n",
      "no groups missing\n",
      "\n",
      "========================================================\n",
      "Current species is CF (CF)\n",
      "\n",
      "GAV not built for radicals. Passing this species.\n",
      "\n",
      "========================================================\n",
      "Current species is CHF (CHF)\n",
      "\n",
      "Estimated thermo via GAV is already good.\n",
      "This is a hydrogen or halogen\n",
      "The matched node used to estimate the GAV was CJ2_singlet-F.\n",
      "No long desc attached to this node.\n",
      "This is a hydrogen or halogen\n",
      "\n",
      "========================================================\n",
      "Current species is CHF(T) (CHF)\n",
      "\n",
      "GAV not built for radicals. Passing this species.\n",
      "\n",
      "========================================================\n",
      "Current species is CH2F (CH2F)\n",
      "\n",
      "GAV not built for radicals. Passing this species.\n",
      "\n",
      "========================================================\n",
      "Current species is CH3F (CH3F)\n",
      "\n",
      "Estimated thermo is off.\n",
      "The best matched node is: CsFHHH\n",
      "There is no data in this best matched group. \n",
      "This is probably a parent node with no specific child.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18083/4279392471.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    108\u001b[0m                                 \u001b[0;31m#let's pass in the parent node to make_group\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                                 \u001b[0mparent_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                                 \u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_degree_neighbor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_degree_neighbor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m                                 \u001b[0mgroup_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_group_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_degree_neighbor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_degree_neighbor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                                 \u001b[0mgroup_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/westgroup/nora/Code/projects/PFAS/AIChE_2024/thermo/helperfunctions.py\u001b[0m in \u001b[0;36mmake_group\u001b[0;34m(atom, parent_node, n_degree_neighbor)\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0mbonds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m     \u001b[0mgroup_atoms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_neighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_atoms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_degree_neighbor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_degree_neighbor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#this is a dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m     \u001b[0;31m# print(group_atoms)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/westgroup/nora/Code/projects/PFAS/AIChE_2024/thermo/helperfunctions.py\u001b[0m in \u001b[0;36mget_neighbors\u001b[0;34m(atom, parent_node, group_atoms, n_degree_neighbor)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;31m#let's look at the specifics of the atoms on the parent node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0matm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparent_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matoms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matomtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0matm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matomtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"O2s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"S2s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"O4tc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0matm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlone_pairs\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# if the parent node does not specify lone pairs, then the child shouldn't have to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'label'"
     ]
    }
   ],
   "source": [
    "#for storing all of the data\n",
    "all_data = dict()\n",
    "all_data[\"entry\"] = list()\n",
    "all_data[\"entry thermo\"] = list()\n",
    "all_data[\"GAE without estimated GAV\"] = list()\n",
    "all_data[\"GAE with estimated GAV\"] = list()\n",
    "all_data[\"missing GAE\"] = list()\n",
    "all_data[\"missing groups\"] = list()\n",
    "\n",
    "missing_group_index_dict = dict()\n",
    "missing_group_dict = dict()\n",
    "missing_group_index = 0\n",
    "\n",
    "good_estimates_with_matched_node = []\n",
    "missing_group_generated = []\n",
    "matched_node_with_bad_estimate = []\n",
    "\n",
    "nodes_that_matched = {}\n",
    "for library in database.libraries:\n",
    "    \n",
    "    entries=list(database.libraries[library].entries.items())\n",
    "    \n",
    "    for item, entry in entries:\n",
    "        \n",
    "        if entry.data is not None:\n",
    "            \n",
    "            if not isinstance(entry.data, ThermoData):\n",
    "                try:\n",
    "                    entry_thermo = entry.data.to_thermo_data()\n",
    "                except:\n",
    "                    continue\n",
    "            else:\n",
    "                entry_thermo = entry.data\n",
    "\n",
    "            molecule = entry.item\n",
    "            print(\"\\n========================================================\")\n",
    "            print(f\"Current species is {entry} ({molecule.get_formula()})\\n\")\n",
    "            \n",
    "            if molecule.smiles in [\"[Ar]\",\"[He]\",\"[Ne]\"]:\n",
    "                #Current group additivity tree only contains C, N, S, O, and some halogen chemistry\n",
    "                #Use `primaryThermoLibrary` for noble gas thermo\n",
    "                continue\n",
    "            if molecule.is_radical():\n",
    "                print('GAV not built for radicals. Passing this species.')\n",
    "            if not molecule.is_radical():\n",
    "                #Current notebook only works on non-radical species.\n",
    "                #Should be able to extend for radical groups with careful adaptation\n",
    "                \n",
    "                estimated_thermo = database.estimate_thermo_via_group_additivity(molecule)\n",
    "                \n",
    "                if (estimated_thermo.H298.value_si-entry_thermo.H298.value_si)/4180 < 2:\n",
    "                    print('Estimated thermo via GAV is already good.')\n",
    "                    molecule.sort_atoms()\n",
    "                    for atom in molecule.atoms:\n",
    "                        if atom.is_non_hydrogen() and not atom.is_halogen():\n",
    "                            node0 = database.groups['group'].descend_tree(molecule, {'*': atom}, None) #this is the node that it matches to. \n",
    "                            data = node0.data\n",
    "                            print(f\"The matched node used to estimate the GAV was {node0}.\")\n",
    "                            if node0.long_desc!= '': \n",
    "                                print(f\"Long desc attached with this node:\\n {node0.long_desc}\")\n",
    "                            if node0.long_desc=='': \n",
    "                                print('No long desc attached to this node.')\n",
    "                            #these can be retrained, but the estimates were good so it won't do much     \n",
    "                            good_estimates_with_matched_node.append(node0)\n",
    "                        else: \n",
    "                            print('This is a hydrogen or halogen')\n",
    "\n",
    "                if (estimated_thermo.H298.value_si-entry_thermo.H298.value_si)/4180 > 2:                    \n",
    "                    print('Estimated thermo is off.')\n",
    "                    \n",
    "                    missing_grp = list()\n",
    "                    missing = 0 #let's count the missing groups\n",
    "\n",
    "                    real_data_thermo = ThermoData(\n",
    "                            Tdata=([300, 400, 500, 600, 800, 1000, 1500], \"K\"),\n",
    "                            Cpdata=([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], \"J/(mol*K)\"),\n",
    "                            H298=(0.0, \"kJ/mol\"),\n",
    "                            S298=(0.0, \"J/(mol*K)\"),\n",
    "                        )\n",
    "\n",
    "                    molecule.sort_atoms()\n",
    "                    \n",
    "                    for atom in molecule.atoms:\n",
    "                            \n",
    "                        #here we loop through each atom. If atom is hydrogen or halogen, we don't descend\n",
    "                        #it down tree because we don't consider hydrogen or halogen as center atom.\n",
    "                        #If the node data is None, string, or all zeros, we go in the branch of generating\n",
    "                        #missing group structure. If the node data is just normal data, we add it to\n",
    "                        #`real_data_thermo`.\n",
    "    \n",
    "                        if atom.is_non_hydrogen() and not atom.is_halogen():\n",
    "                            #Hydrogen and halogen are not considered as center atom\n",
    "\n",
    "                            node0 = database.groups['group'].descend_tree(molecule, {'*': atom}, None) #this is the best matched node\n",
    "                            node = node0\n",
    "                            data = node.data\n",
    "\n",
    "                            add_to_real_data_thermo = True\n",
    "                            print(f\"The best matched node is: {node}\")\n",
    "                            \n",
    "                            ###############################################################################\n",
    "                                #Start identifying missing group\n",
    "                            if data is None or isinstance(data,str) or data.is_all_zeros():\n",
    "                                print('There is no data in this best matched group. \\nThis is probably a parent node with no specific child.')\n",
    "                                \n",
    "                                #make group structure and group string\n",
    "                                n_degree_neighbor = 1\n",
    "                                #let's pass in the parent node to make_group\n",
    "                                parent_node = node0\n",
    "                                group = make_group(atom, parent_node, n_degree_neighbor=n_degree_neighbor)\n",
    "                                group_str = make_group_name(atom, n_degree_neighbor=n_degree_neighbor)\n",
    "                                group_0 = group\n",
    "                                group_str_0 = group_str\n",
    "                                print(f\"First initial generated group is: {group_str_0}\")\n",
    "                                print(group_0.to_adjacency_list())\n",
    "                                \n",
    "                                if group_str.split(\"_\")[-1] not in special_list:\n",
    "                                    \n",
    "                                    while not group.is_subgraph_isomorphic(node.item):\n",
    "                                    #while not group.is_subgraph_isomorphic(node.item, generate_initial_map = True):#Su suggested this\n",
    "                                        #new group has to be the child-node of the originally matched group\n",
    "                                        #to have correct parent-node child-node relation\n",
    "                                        print(f\"newly made group \\n{group.to_adjacency_list()} is not subgraph isomorphic to the parent node {node} \\n{node.item.to_adjacency_list()}\")\n",
    "                                        print(\"Increasing n_degree_neighbor and trying again.\")\n",
    "                                        n_degree_neighbor+=1\n",
    "                                        group = make_group(atom, parent_node, n_degree_neighbor=n_degree_neighbor)\n",
    "                                        group_str = make_group_name(atom, n_degree_neighbor=n_degree_neighbor)\n",
    "                                    print('Newly made child group passed check for being sub-iso to parent node')\n",
    "                                    while any([(group.make_sample_molecule()).is_subgraph_isomorphic(child.item, generate_initial_map = True) for child in node.children]):\n",
    "                                        #Child-node can't be the child of other children\n",
    "                                        #to avoid ambiguous group selection\n",
    "                                        n_degree_neighbor+=1\n",
    "                                        group = make_group(atom, parent_node, n_degree_neighbor=n_degree_neighbor)\n",
    "                                        group_str = make_group_name(atom, n_degree_neighbor=n_degree_neighbor)\n",
    "                                    print('Newly made child group passed check to not being sub-iso to other children of the parent node.')\n",
    "                                if group_str.split(\"_\")[-1] not in special_list:\n",
    "                                    add_to_real_data_thermo = False \n",
    "\n",
    "                                    group.sort_atoms()\n",
    "                                                  \n",
    "                                                  #parent label  #new label\n",
    "                                    group_str = f'{node.label}_{group_str}'\n",
    "\n",
    "                                    missing += 1 #increase count for missing groups for this molecule\n",
    "                                    missing_grp.append(group_str) \n",
    "                                    missing_group_generated.append(group_str)\n",
    "                                    if group_str not in missing_group_index_dict:\n",
    "                                        missing_group_index_dict[group_str] = missing_group_index\n",
    "                                        missing_group_index+=1\n",
    "\n",
    "                                        missing_group_dict[group_str] = dict()\n",
    "                                        missing_group_dict[group_str][\"group\"] = [group]\n",
    "                                        missing_group_dict[group_str][\"atom\"] = [atom]\n",
    "                                        missing_group_dict[group_str][\"molecule\"] = [molecule]\n",
    "                                        missing_group_dict[group_str][\"label\"] = [entry.label]\n",
    "                                    else:\n",
    "                                        missing_group_dict[group_str][\"group\"].append(group)\n",
    "                                        missing_group_dict[group_str][\"atom\"].append(atom)\n",
    "                                        missing_group_dict[group_str][\"molecule\"].append(molecule)\n",
    "                                        missing_group_dict[group_str][\"label\"].append(entry.label)\n",
    "\n",
    "                ###############################################################################\n",
    "                #calculate real data thermo value\n",
    "                            if add_to_real_data_thermo: #this only happens if it is not a missing group.\n",
    "                                while node is not None and node.data is None:\n",
    "                                    node = node.parent #if there is no data in this node, go up to the parent with data. \n",
    "                                if node is None:\n",
    "                                    raise DatabaseError(f'Unable to determine thermo parameters for atom {atom} in molecule {molecule}: '\n",
    "                                                        f'no data for node {node0} or any of its ancestors in database {database.label}.')\n",
    "\n",
    "                                data = node.data\n",
    "                                comment = node.label\n",
    "                                loop_count = 0\n",
    "                                while isinstance(data, str):\n",
    "                                    loop_count += 1\n",
    "                                    if loop_count > 100:\n",
    "                                        raise DatabaseError(\"Maximum iterations reached while following thermo group data pointers. A circular\"\n",
    "                                                            f\" reference may exist. Last node was {node.label} pointing to group called {data} in \"\n",
    "                                                            f\"database {database.label}\")\n",
    "\n",
    "                                    for entr in database.groups[\"group\"].entries.values():\n",
    "                                        if entr.label == data:\n",
    "                                            data = entr.data\n",
    "                                            comment = entr.label\n",
    "                                            break\n",
    "                                    else:\n",
    "                                        raise DatabaseError(f\"Node {node.label} points to a non-existing group called {data} \"\n",
    "                                                            f\"in database {database.label}\")\n",
    "\n",
    "                                data.comment = '{0}({1})'.format(database.groups['group'].label, comment)\n",
    "                                print('Adding thermo data ') \n",
    "                                matched_node_with_bad_estimate.append(node)\n",
    "                                add_thermo_data(real_data_thermo, data, group_additivity=True)\n",
    "\n",
    "                    cyclic = molecule.is_cyclic()\n",
    "\n",
    "                    if cyclic:\n",
    "                        sssr = molecule.get_smallest_set_of_smallest_rings()\n",
    "                        for ring in sssr:\n",
    "                            for atomPair in itertools.permutations(ring, 2):\n",
    "                                try:\n",
    "                                    database._add_group_thermo_data(real_data_thermo, database.groups['longDistanceInteraction_cyclic'], molecule,\n",
    "                                                                {'*1': atomPair[0], '*2': atomPair[1]})\n",
    "                                except KeyError:\n",
    "                                    pass\n",
    "\n",
    "                    # Do ring corrections separately because we only want to match\n",
    "                    # each ring one time\n",
    "\n",
    "                    if cyclic:\n",
    "                        monorings, polyrings = molecule.get_disparate_cycles()\n",
    "                        for ring in monorings:\n",
    "                            # Make a temporary structure containing only the atoms in the ring\n",
    "                            # NB. if any of the ring corrections depend on ligands not in the ring, they will not be found!\n",
    "                            try:\n",
    "                                database._add_ring_correction_thermo_data_from_tree(real_data_thermo, database.groups['ring'], molecule, ring)\n",
    "                            except KeyError:\n",
    "                                logging.error(\"Couldn't find a match in the monocyclic ring database even though \"\n",
    "                                              \"monocyclic rings were found.\")\n",
    "                                logging.error(molecule)\n",
    "                                logging.error(molecule.to_adjacency_list())\n",
    "                                raise\n",
    "                        for polyring in polyrings:\n",
    "                            # Make a temporary structure containing only the atoms in the ring\n",
    "                            # NB. if any of the ring corrections depend on ligands not in the ring, they will not be found!\n",
    "                            try:\n",
    "                                database._add_polycyclic_correction_thermo_data(real_data_thermo, molecule, polyring)\n",
    "                            except KeyError:\n",
    "                                logging.error(\"Couldn't find a match in the polycyclic ring database even though \"\n",
    "                                              \"polycyclic rings were found.\")\n",
    "                                logging.error(molecule)\n",
    "                                logging.error(molecule.to_adjacency_list())\n",
    "\n",
    "    ########################################################################################################\n",
    "                    if missing > 0:\n",
    "            #If there are missing groups identified in this molecule, add to all_data (dict)\n",
    "                        entry.short_desc = library\n",
    "                        all_data[\"entry\"].append(entry)\n",
    "                        all_data[\"GAE without estimated GAV\"].append(real_data_thermo)\n",
    "                        all_data[\"GAE with estimated GAV\"].append(estimated_thermo)\n",
    "                        all_data[\"missing groups\"].append(missing_grp)\n",
    "                        all_data[\"entry thermo\"].append(entry_thermo)\n",
    "\n",
    "                        try:\n",
    "                            #we remove the contribution from `real_data_thermo` in the old thermo estimation\n",
    "                            #the rest of thermo are contributed by the missing groups\n",
    "                            missing_group_thermo = remove_thermo_data(deepcopy(entry_thermo),real_data_thermo)\n",
    "                            all_data[\"missing GAE\"].append(missing_group_thermo)\n",
    "                        except (ValueError,IndexError):\n",
    "                            #We need Cp0 and CpInf to perform the inversion from Nasa to ThermoData\n",
    "                            if entry_thermo.Cp0 is None:\n",
    "                                cp_0 = molecule.calculate_cp0()\n",
    "                                entry_thermo.Cp0 = (cp_0, \"J/(mol*K)\")\n",
    "                            if entry_thermo.CpInf is None:\n",
    "                                cp_inf = molecule.calculate_cpinf()\n",
    "                                entry_thermo.CpInf = (cp_inf, \"J/(mol*K)\")\n",
    "\n",
    "                            nasa = entry_thermo.to_nasa(Tmin=10.0, Tmax=3000.0, Tint=500.0)\n",
    "                            entry_thermo = nasa.to_thermo_data()\n",
    "                            missing_group_thermo = remove_thermo_data(deepcopy(entry_thermo),real_data_thermo)\n",
    "                            all_data[\"missing GAE\"].append(missing_group_thermo)\n",
    "                    if missing == 0:\n",
    "                        #if there are no missing groups, let's isolate these species and do something with them later\n",
    "                        print('no groups missing')\n",
    "        # print('completed')\n",
    "spc_num = len(all_data[\"entry\"])\n",
    "grp_num = len(missing_group_index_dict.keys())\n",
    "print(f\"Fitting {grp_num} of new groups with {spc_num} of species\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ecfa6a9-0b06-42b3-8e8c-78cf6b2f342e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[<AtomType \"Cs\">]'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(node.item.atoms[0].atomtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7d7f91-424f-4a0b-950e-e58a239ec9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of matched nodes that provided good GAV: {len(set(good_estimates_with_matched_node))}')\n",
    "print(f'Number of matched nodes that provided poor GAV: {len(set(matched_node_with_bad_estimate))}')\n",
    "print(f'Number of missing groups: {len(set(missing_group_generated))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d459047-db78-4308-9312-e474701d9f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "for atom in node.item.atoms:\n",
    "    print(atom.lone_pairs)\n",
    "    if atom.lone_pairs==[]:\n",
    "        print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a304f83-ee86-4ded-b7fb-1720a8a5a379",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = good_estimates_with_matched_node+matched_node_with_bad_estimate\n",
    "accounting_for_overlap = set(combined)\n",
    "print(f'We will have to retrain {len(accounting_for_overlap)} nodes with existing data\\nand add in {len(set(missing_group_generated))} new groups.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f40685-ce98-45e9-955b-03d344df62df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(node.item.to_adjacency_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ea39ce-2000-44fe-b488-57dc9e203c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "node.item.atoms[2].charge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979cd6c1-4190-4d26-9203-502d8f490d79",
   "metadata": {},
   "source": [
    "# Deleting data from these selected nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c252cf57-4dc9-42d1-a4e0-1a4d0b6cd11a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#let's get the indices of the combined list\n",
    "indices_of_existing_matches = [ node.index for node in list(accounting_for_overlap)]\n",
    "\n",
    "database_new = deepcopy(database)\n",
    "for group_label, entry in database_new.groups['group'].entries.items(): \n",
    "    if entry.index in indices_of_existing_matches: \n",
    "        print(f'Index {entry.index}')\n",
    "        print(f'Previous thermo data for node: \\n{entry.data}')\n",
    "        zero_thermo_data = ThermoData(\n",
    "                            Tdata=([300, 400, 500, 600, 800, 1000, 1500], \"K\"),\n",
    "                            Cpdata=([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], \"J/(mol*K)\"),\n",
    "                            H298=(0.0, \"kJ/mol\"),\n",
    "                            S298=(0.0, \"J/(mol*K)\"),\n",
    "                        )\n",
    "        #now rewrite the data of entry to be nothing \n",
    "        print(entry.item.to_adjacency_list())\n",
    "        entry.data = zero_thermo_data\n",
    "        assert entry.data.is_all_zeros()==True, \"This one wasn't changed\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9e2f97-a782-4b06-9cc7-c25ac39b41c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now save this now groups.py file \n",
    "database_new.groups[\"group\"].save(\"./group.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de3b45d-d0fd-4ced-bf3f-a347bb83167f",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_of_existing_matches"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rmg_env",
   "language": "python",
   "name": "rmg_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
